<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jumman Hossain</title>

    <meta name="author" content="Jumman Hossain">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jumman Hossain
                </p>
                <p>I'm a PhD researcher at <a href="https://www.umbc.edu/">UMBC</a> in the <a href="https://mpsc.umbc.edu/">Mobile, Pervasive, and Sensor Computing (MPSC) Lab</a>, specializing in reinforcement learning (RL) and machine learning (ML) for autonomous systems and robotics. I focus on optimizing decision-making in complex environments.</p> <br>
                <p>During my Summer 2024 internship at <a href="https://www.stormfish.io" target="_blank">Stormfish Scientific Corporation</a>, I developed reinforcement learning models for navigation in XR simulations using <strong>AuroraXR®</strong>. My work focused on enhancing multi-robot coordination in contested environments, utilizing real-time synchronization between virtual and physical robots through the AuroraXR ROS Bridge.</p>
                <div class="internship-seeking" style="background-color: #f0f8ff; padding: 15px; border-radius: 8px;">
                <p style="color: #2c3e50; font-weight: bold;">
                  I am currently seeking a <span style="color: #e74c3c;">Full time/Summer internship</span> where I can apply my expertise in <span style="color: #3498db;">reinforcement learning</span>, <span style="color: #2ecc71;">robotics</span>, and <span style="color: #f1c40f;">machine learning</span> to solve challenging real-world problems. </p>
              </div>

                <p style="text-align:center">
                  <a href="mailto:jummanhossain92@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Jumman_Hossain_Resume'24_Page.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=depfbYkAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/pralgomathic">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/pralgomathic/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/jumman_mpsc.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/jumman_mpsc.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
       <table
  style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading style="text-decoration:underline;">News</heading>
        <ul>
          <li>2024.10: Our paper <a href="#">"Learning Optimal Policies with Quasi-Potential Functions for Asymmetric Traversal"</a> is under review for <em><span style='color:blue;'>AAMAS 2025</span></em>.</li>
          <li>2024.10: Our new pre-print is out! (Under Review)<br>
            <a href="#">"SERN: Simulation-Enhanced Realistic Navigation for Multi-Agent Robotic Systems in Contested Environments"</a>
          </li>
          <li>2024.10:  Our new pre-print is out! (Under Review)<br>
            <a href="#">"QuasiNav: Asymmetric Cost-Aware Navigation Planning with Constrained Quasimetric Reinforcement Learning"</a>
          </li>
          <li>2024.10: Paper accepted at <em><span style='color:green;'>IROS 2024</span></em>!<br>
            <a href="#">"TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments"</a>
          </li>
          <li>2024.10: Paper accepted at <em><span style='color:brown;'>ACSOS 2024</span></em>!<br>
            <a href="#">"EnCoMP: Enhanced Covert Maneuver Planning with Adaptive Target-Aware Visibility Estimation using Offline Reinforcement Learning"</a>
          </li>
          <li>2024.08: Completed a PhD Research Internship at <em>Stormfish Scientific Corporation</em>, focusing on XR military simulations and RL models for off-road environments.</li>

          <li>2023.08: Contributed to <a href="#">"Remote Robotic Experimentation with Distributed Virtual Proving Ground (DVPG)"</a>, showcasing adaptive SLAM and multi-robot field experimentation capabilities.</li>
         <li>2023.10: Paper accepted at <em><span style='color:purple;'>ACSOS 2023</span></em>!<br>
            <a href="#">"CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environments with Deep Reinforcement Learning"</a>
          </li>
          <li>2022.06: Published (Collaboration) <a href="#">"SynchroSim: An Integrated Co-simulation Middleware for Heterogeneous Multi-robot Systems"</a> at <em><span style='color:teal;'>IEEE DCOSS 2022</span></em>.</li>
          <li>2022.05: Published (Collaboration) <a href="#">"Simulated Forest Environment and Robot Control Framework for Integration with Cover Detection Algorithms"</a> in <em><span style='color:darkcyan;'>IEEE/ACM BDCAT 2022</span></em>.</li>
          <li>2021.08: Started my research on reinforcement learning and robotics at UMBC, joining the Mobile, Pervasive, and Sensor Computing (MPSC) Lab.</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>My interests lie in reinforcement learning, autonomous navigation, and robotics. I am passionate about advancing autonomous navigation through learning-based optimization techniques. My work focuses on developing algorithms for better understanding and interaction with physical environments—optimizing exploration, navigation, and motion planning, especially in sparse-reward and challenging scenarios.</p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
       
        <tr onmouseout="paper2_stop()" onmouseover="paper2_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='paper2_image'>
                <img src='images/QuasiNav_navigation_scenario_2.jpg' width="100%">
              </div>
              <img src='images/QuasiNav_navigation_scenario.jpg' width="100%">
            </div>
            <script type="text/javascript">
              function paper2_start() {
                document.getElementById('paper2_image').style.opacity = "1";
              }
        
              function paper2_stop() {
                document.getElementById('paper2_image').style.opacity = "0";
              }
              paper2_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://link-to-your-paper">
              <span class="papertitle">QuasiNav: Asymmetric Cost-Aware Navigation Planning with Constrained Quasimetric Reinforcement Learning</span>
            </a>
           
            <br>
            <strong>Jumman Hossain</strong>, Abu Zaher Faridee, Nirmalya Roy, Jade Freeman, Timothy Gregory, Theron Trout
            <br>
            
            <em>ICRA 2025 (Under Review)</em> <br>
            <a href="https://link-to-project-page">project page</a> /
            <a href="https://arxiv.org/abs/2410.16666">arXiv</a>
            <p></p>
            <p>
              This paper presents an asymmetric cost-aware navigation method using quasimetric-constrained policy optimization to improve navigation planning in complex, real-world environments with uneven costs and constraints.
            </p>
          </td>
        </tr>

      <tr onmouseout="paper3_stop()" onmouseover="paper3_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='paper3_image'>
              <img src='images/virtual_world.png' width="100%"> 
            </div>
            <img src='images/AuroraXR_Sern_Overview1.png' width="100%"> 
          </div>
          <script type="text/javascript">
            function paper3_start() {
              document.getElementById('paper3_image').style.opacity = "1";
            }
      
            function paper3_stop() {
              document.getElementById('paper3_image').style.opacity = "0";
            }
            paper3_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://link-to-your-paper">
            <span class="papertitle">SERN: Simulation-Enhanced Realistic Navigation for Multi-Agent Robotic Systems in Contested Environments</span>
          </a>
          <br>
          <strong>Jumman Hossain</strong>, Emon Dey, Snehalraj Chugh, Masud Ahmed, MS Anwar, Abu-Zaher Faridee, Jason Hoppes, Theron Trout, Anjon Basak, Rafidh Chowdhury, Rishabh Mistry, Hyun Kim, Jade Freeman, Niranjan Suri, Adrienne Raglin, Carl Busart, Timothy Gregory, Anuradha Ravi, Nirmalya Roy
          <br>
          <em>ICRA 2025 (Under Review)</em>
          <br>
          <a href="https://youtu.be/BqNoqDPqhNc">Video</a> /
          <a href="https://arxiv.org/abs/2410.16686">arXiv</a>
          <p></p>
          <p>
            This paper introduces a simulation-enhanced approach for realistic navigation planning in multi-agent robotic systems, optimizing strategies for operations in contested and unpredictable environments.
          </p>
        </td>
      </tr>
                    <!-- TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments (IROS 2024) -->
        <tr onmouseout="paper4_stop()" onmouseover="paper4_start()"  bgcolor="#ffebc7">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='paper4_image'>
                <img src='images/TopoNav_Navigation_Strategy_2.png' width="100%">
              </div>
              <img src='images/TopoNav_Navigation_Strategy.png' width="100%">
            </div>
            <script type="text/javascript">
              function paper4_start() {
                document.getElementById('paper4_image').style.opacity = "1";
              }
        
              function paper4_stop() {
                document.getElementById('paper4_image').style.opacity = "0";
              }
              paper4_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://link-to-your-paper">
              <span class="papertitle">TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments</span>
            </a>
            <br>
            <strong>Jumman Hossain</strong>, Abu Zaher Faridee, Nirmalya Roy, Jade Freeman, Timothy Gregory, Theron Trout
            <br>
            <em>IROS 2024</em> <br>
            <a href="https://youtu.be/lcD6F-SXcss">Video</a> /
                  <a href="https://arxiv.org/abs/2402.04061">arXiv</a>
            <p></p>
            <p> A navigation framework that leverages hierarchical reinforcement learning (HRL) to enable autonomous robots to efficiently explore unknown areas. By building active topological maps and incorporating intrinsic rewards, TopoNav enhances navigation accuracy and adaptability, especially in sparse-reward environments.</p>
          </td>
        </tr>
        
        <!-- EnCoMP: Enhanced Covert Maneuver Planning with Adaptive Target-Aware Visibility Estimation using Offline Reinforcement Learning (ACSOS 2024) -->
        <tr onmouseout="paper5_stop()" onmouseover="paper5_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='paper5_image'>
                <img src='images/encomp_target_map_visualization.png' width="100%">
              </div>
              <img src='images/encomp_covert_planning.jpg' width="100%"> 
            </div>
            <script type="text/javascript">
              function paper5_start() {
                document.getElementById('paper5_image').style.opacity = "1";
              }
        
              function paper5_stop() {
                document.getElementById('paper5_image').style.opacity = "0";
              }
              paper5_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/document/10771229">
              <span class="papertitle">EnCoMP: Enhanced Covert Maneuver Planning with Adaptive Target-Aware Visibility Estimation using Offline Reinforcement Learning</span>
            </a>
            <br>
            <strong>Jumman Hossain</strong>, Abu Zaher Faridee, Nirmalya Roy, Jade Freeman, Timothy Gregory, Theron Trout
            <br>
            <em>ACSOS 2024</em> <br>
             <a href="https://arxiv.org/abs/2403.20016">arXiv</a>
            <p></p>
            <p>This approach enhances maneuver planning by using target-aware visibility estimations and offline reinforcement learning, making it highly suitable for complex and contested environments where maintaining cover is critical. </p>
          </td>
        </tr>
        

            <!-- CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning (ACSOS 2023) -->
          <tr onmouseout="paper6_stop()" onmouseover="paper6_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='paper6_image'>
                  <img src='images/covernav_system_architecture_03.png' width="100%">
                </div>
                <img src='images/CoverNav_Navigation.png' width="100%">
              </div>
              <script type="text/javascript">
                function paper6_start() {
                  document.getElementById('paper6_image').style.opacity = "1";
                }
          
                function paper6_stop() {
                  document.getElementById('paper6_image').style.opacity = "0";
                }
                paper6_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/10336033">
                <span class="papertitle">CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning</span>
              </a>
              <br>
              <strong>Jumman Hossain</strong>, Abu Zaher Faridee, Anjon Basak, Derrik Asher, Nirmalya Roy
              <br>
              <em>ACSOS 2023</em>
              <br>
              <a href="https://arxiv.org/abs/2308.06594">arXiv</a>
              <p></p>
              <p>
                CoverNav presents a deep reinforcement learning approach for navigation planning that prioritizes cover following in unstructured outdoor environments.
              </p>
            </td>
          </tr>



            <!-- SynchroSim: An Integrated Co-simulation Middleware for Heterogeneous Multi-robot System (IEEE DCOSS 2022) -->
          <tr onmouseout="paper7_stop()" onmouseover="paper7_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='paper7_image'>
                  <img src='images/synchrosim_nnlos.png' width="100%">
                </div>
                <img src='images/synchrosim_overview.jpg' width="100%">
              </div>
              <script type="text/javascript">
                function paper7_start() {
                  document.getElementById('paper7_image').style.opacity = "1";
                }
          
                function paper7_stop() {
                  document.getElementById('paper7_image').style.opacity = "0";
                }
                paper7_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9881671">
                <span class="papertitle">SynchroSim: An Integrated Co-simulation Middleware for Heterogeneous Multi-robot System</span>
              </a>
              <br>
              Emon Dey, <strong>Jumman Hossain</strong>, Nirmalya Roy, Carl Busart
              <br>
              <em>IEEE DCOSS 2022</em>
              <br>
              <a href="https://arxiv.org/abs/2208.06569">arXiv</a>
              <p></p>
              <p>
                SynchroSim provides an integrated co-simulation middleware that supports coordination and interaction among heterogeneous multi-robot systems. It ensures effective communication and synchronization across diverse platforms, allowing robust development and testing of cooperative robotic applications in dynamic environments.
              </p>
            </td>
          </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  I utilized source code from <a href="https://github.com/jonbarron/jonbarron_website">here</a> to create this website.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
